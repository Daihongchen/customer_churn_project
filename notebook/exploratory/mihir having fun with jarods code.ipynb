{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "df = pd.read_csv('../../data/Customer Churn Data.csv')\n",
    "#Turn International Plan from a categorical variable to binary (yes = 1, no = 0)\n",
    "df['international plan'] = (df['international plan'] == 'yes').astype(int)\n",
    "#Turn Voice Mail Plan from a categorical variable to binary (yes = 1, no = 0)\n",
    "df['voice mail plan'] = (df['voice mail plan'] == 'yes').astype(int)\n",
    "#Initiate OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse = False)\n",
    "#Create an ohe_states DF where you split the state column into new columns with the state name \n",
    "ohe_states = pd.DataFrame(ohe.fit_transform(pd.DataFrame(df['state'])), columns = ohe.get_feature_names())\n",
    "#Combine the 2 dataframes \n",
    "df = pd.concat([df, ohe_states], axis = 1)\n",
    "#Drop state and area code (irrelevant)\n",
    "df = df.drop(['state'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set target variable as churn\n",
    "y = df['churn']\n",
    "#Copy X\n",
    "X = df.copy()\n",
    "#Drop churn and phone number from X (could have dropped phone number earlier)\n",
    "X.drop(['churn', 'area code','phone number'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the initial data into train and holdout (holdout is for final evaluation)\n",
    "X_train, X_holdout, y_train, y_holdout = train_test_split(X, y)\n",
    "#Split train into a train and test set (to build your model)\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_train, y_train)\n",
    "\n",
    "#Initiate a standard scaler \n",
    "ss = StandardScaler()\n",
    "#Scale X_train and X_test \n",
    "X_train1 = ss.fit_transform(X_train1)\n",
    "X_test1 = ss.transform(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9845250800426895"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set our estimators, 4 classification models\n",
    "#Questions: What is solver \"Liblinear\"?\n",
    "\n",
    "estimators = [('knn', KNeighborsClassifier(n_neighbors = 20)),   \n",
    "              ('rf', RandomForestClassifier(n_estimators = 100)),\n",
    "              ('grad', GradientBoostingClassifier())]\n",
    "\n",
    "#Initiate a stack classifier\n",
    "\n",
    "stack = StackingClassifier(estimators = estimators, final_estimator = LogisticRegression(), cv = 5)\n",
    "\n",
    "#Fit the model to our sub-train data \n",
    "\n",
    "stack.fit(X_train1, y_train1);\n",
    "\n",
    "#Calculate accuracy score \n",
    "\n",
    "stack.score(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9456\n",
      "Precision: 0.828125\n",
      "Recall: 0.6973684210526315\n",
      "F1: 0.7571428571428572\n"
     ]
    }
   ],
   "source": [
    "#Evaluate metrics of our model based on the sub-test data \n",
    "#Accuracy is # of predictions our model got right (correct/total)\n",
    "#Precision is when it guessed true, how many times was it correct (# of correct positive/total positive) \n",
    "#Recall is how many actual positives were guessed correctly (true positives/true positives + false negatives)\n",
    "#Since false negatives are considered actual positives \n",
    "#F1 score is balance between precision and recall \n",
    "\n",
    "metrics(y_test1, stack.predict(X_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function that prints the scores \n",
    "\n",
    "def metrics(y_true, y_pred):\n",
    "    print('Accuracy: ' + str(accuracy_score(y_true, y_pred)))\n",
    "    print('Precision: ' + str(precision_score(y_true, y_pred)))\n",
    "    print('Recall: ' + str(recall_score(y_true, y_pred)))\n",
    "    print('F1: ' + str(f1_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8784\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1: 0.0\n",
      "Accuracy: 0.9424\n",
      "Precision: 0.9545454545454546\n",
      "Recall: 0.5526315789473685\n",
      "F1: 0.7000000000000001\n",
      "Accuracy: 0.944\n",
      "Precision: 0.8153846153846154\n",
      "Recall: 0.6973684210526315\n",
      "F1: 0.7517730496453899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jarodc33/opt/anaconda3/envs/customerchurn/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Write a for loop to print metrics for each model \n",
    "\n",
    "for i in stack.estimators_:\n",
    "    metrics(y_test1, i.predict(X_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (customerchurn)",
   "language": "python",
   "name": "customerchurn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
